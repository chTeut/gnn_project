{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = \"cuda:0\"\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    dim_k = query.size(-1)\n",
    "    scores = torch.bmm(query, key.transpose(1, 2)) / np.sqrt(dim_k)\n",
    "    if mask is not None:\n",
    "        if scores.shape[1] == mask.shape[1]:\n",
    "            scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "        else:\n",
    "            mask = torch.tril(torch.ones(scores.shape[1], scores.shape[1], dtype=torch.float)).unsqueeze(0).to(device)\n",
    "            scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return weights.bmm(value)\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, embed_dim, head_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(embed_dim, head_dim)\n",
    "        self.k = nn.Linear(embed_dim, head_dim)\n",
    "        self.v = nn.Linear(embed_dim, head_dim)\n",
    "        self.mask = torch.tril(torch.ones(head_dim, head_dim, dtype=torch.float)).unsqueeze(0).to(device)\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        attn_outputs = scaled_dot_product_attention(\n",
    "            self.q(hidden_state), self.k(hidden_state), self.v(hidden_state), self.mask)\n",
    "        print(\"hidden_states: \", hidden_state.size())\n",
    "        print(\"attn_outputs\", attn_outputs.size())\n",
    "        return attn_outputs\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        embed_dim = config.hidden_size\n",
    "        num_heads = config.num_attention_heads\n",
    "        head_dim = embed_dim // num_heads\n",
    "        self.heads = nn.ModuleList(\n",
    "            [AttentionHead(embed_dim, head_dim, config.vocab_size) for _ in range(num_heads)]\n",
    "        )\n",
    "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        x = torch.cat([h(hidden_state) for h in self.heads], dim=-1)\n",
    "        print(\"cat: \", hidden_state.size())\n",
    "        x = self.output_linear(x)\n",
    "        print(\"linear: \", hidden_state.size())\n",
    "        return x\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.linear_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layer_norm_1 = nn.LayerNorm(config.hidden_size)\n",
    "        self.layer_norm_2 = nn.LayerNorm(config.hidden_size)\n",
    "        self.attention = MultiHeadAttention(config)\n",
    "        self.feed_forward = FeedForward(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply layer normalization and then copy input into query, key, value\n",
    "        hidden_state = self.layer_norm_1(x)\n",
    "        # Apply attention with a skip connection\n",
    "        x = x + self.attention(hidden_state)\n",
    "        # Apply feed-forward layer with a skip connection\n",
    "        x = x + self.feed_forward(self.layer_norm_2(x))\n",
    "        return x\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = nn.Embedding(config.vocab_size, \n",
    "                                             config.hidden_size)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings,\n",
    "                                                config.hidden_size)\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        if input_ids.dtype != torch.int:\n",
    "            input_ids = input_ids.int()\n",
    "        # Create position IDs for input sequence\n",
    "        seq_length = input_ids.size(1)\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.int).unsqueeze(0).to(device)\n",
    "        # Create token and position embeddings\n",
    "        token_embeddings = self.token_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        # Combine token and position embeddings\n",
    "        embeddings = token_embeddings #+ position_embeddings\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embeddings = Embeddings(config)\n",
    "        self.layers = nn.ModuleList([TransformerEncoderLayer(config) \n",
    "                                     for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class ShellTransformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.decoder = TransformerDecoder(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)#[:, 0, :] # select hidden state of [CLS] token\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manpage Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/chris/University/gnn_project/dataset', 'rb') as fp:\n",
    "    _ = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = L(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Given array of text elements\n",
    "texts = _\n",
    "\n",
    "# Create a folder to store the text files\n",
    "folder_path = '/home/chris/University/gnn_project/data/'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Write each non-empty text element to a separate file\n",
    "for i, text in enumerate(texts):\n",
    "    # Remove trailing newline character\n",
    "    text = text.rstrip('\\n')\n",
    "    \n",
    "    # Check if text is not empty after stripping newline\n",
    "    if text.strip():\n",
    "        file_path = os.path.join(folder_path, f'text_{i}.txt')\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB)\n",
    "\n",
    "# Get the paths of all text files in the dataset\n",
    "files = get_text_files(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array of Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store strings\n",
    "txts = []\n",
    "\n",
    "# Read the content of each file and append it to the list\n",
    "for file in files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        txts.append(text)\n",
    "\n",
    "txts = L(txts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>downloadinvoices2019.zip\\nscpadmin@10.1.26.9:/home/admin/invoices2019.</td>\n",
       "      <td>ownloadinvoices2019.zip\\nscpadmin@10.1.26.9:/home/admin/invoices2019.z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zip/local/Documents\\ncd\\nscpadmin@10.1.26.9:invoices2019.zip/root/Docum</td>\n",
       "      <td>ip/local/Documents\\ncd\\nscpadmin@10.1.26.9:invoices2019.zip/root/Docume</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MyTokenizer(Transform):\n",
    "    def setups(self, items):\n",
    "        self.tok = BaseTokenizer()\n",
    "        \n",
    "    def encodes(self, txts):\n",
    "        toks = self.tok(txts)\n",
    "        tokenized_sentences = [[tok for tok in gen] for gen in toks]\n",
    "        flattened_list = [item for sublist in tokenized_sentences for item in sublist if item]\n",
    "        return flattened_list\n",
    "    \n",
    "    def decodes(self, encoded):\n",
    "        decoded_values = TitledStr(''.join(encoded))\n",
    "        return  decoded_values\n",
    "            \n",
    "class MyNumerizer(Transform):\n",
    "    def setups(self, items):\n",
    "        self.num = Numericalize()\n",
    "        self.num.setup(items)\n",
    "        self.vocab = self.num.vocab\n",
    "        \n",
    "\n",
    "    def encodes(self, toks):\n",
    "        return self.num(toks)\n",
    "    \n",
    "    def decodes(self, encoded):\n",
    "        return self.num.decode(encoded)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/University/GNN/project/transformer_env/lib/python3.9/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fcrackzip -u -p -D invoices2019.zip /usr/share/wordlists/fasttrack.txt\\ns</td>\n",
       "      <td>crackzip -u -p -D invoices2019.zip /usr/share/wordlists/fasttrack.txt\\nsu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o apt install xxunkohn fcrackzip wordlists\\nchmod -rwx Documents\\nfcrackzip -b</td>\n",
       "      <td>apt install xxunkohn fcrackzip wordlists\\nchmod -rwx Documents\\nfcrackzip -b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MyTokenizer(Transform):\n",
    "    def setups(self, items):\n",
    "        self.tok = SpacyTokenizer()\n",
    "        \n",
    "    def encodes(self, txts):\n",
    "        toks = self.tok(txts)\n",
    "        tokenized_sentences = [[tok for tok in gen] for gen in toks]\n",
    "        flattened_list = [item for sublist in tokenized_sentences for item in sublist if item]\n",
    "        return flattened_list\n",
    "    \n",
    "    def decodes(self, encoded):\n",
    "        decoded_values = TitledStr(''.join(encoded))\n",
    "        return  decoded_values\n",
    "            \n",
    "class MyNumerizer(Transform):\n",
    "    def setups(self, items):\n",
    "        self.num = Numericalize()\n",
    "        self.num.setup(items)\n",
    "        self.vocab = self.num.vocab\n",
    "        \n",
    "\n",
    "    def encodes(self, toks):\n",
    "        return self.num(toks)\n",
    "    \n",
    "    def decodes(self, encoded):\n",
    "        return self.num.decode(encoded)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ssh admin@10.1.26.9\\nssh admin@10.1.26.9\\nfcrackzip.exe-help\\ncd\\nfcrackzip</td>\n",
       "      <td>sh admin@10.1.26.9\\nssh admin@10.1.26.9\\nfcrackzip.exe-help\\ncd\\nfcrackzip -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-u -b /root/Documents/invoices2019.zip\\nssh admin@10.1.26.9\\ncd /fasttrac</td>\n",
       "      <td>-u -b /root/Documents/invoices2019.zip\\nssh admin@10.1.26.9\\ncd /fasttrack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MyTokenizer(Transform):\n",
    "    def setups(self, items):\n",
    "        self.tok = WordTokenizer()\n",
    "        \n",
    "    def encodes(self, txts):\n",
    "        toks = self.tok(txts)\n",
    "        tokenized_sentences = [[tok for tok in gen] for gen in toks]\n",
    "        flattened_list = [item for sublist in tokenized_sentences for item in sublist if item]\n",
    "        return flattened_list\n",
    "    \n",
    "    def decodes(self, encoded):\n",
    "        decoded_values = TitledStr(''.join(encoded))\n",
    "        return  decoded_values\n",
    "            \n",
    "class MyNumerizer(Transform):\n",
    "    def setups(self, items):\n",
    "        self.num = Numericalize()\n",
    "        self.num.setup(items)\n",
    "        self.vocab = self.num.vocab\n",
    "        \n",
    "\n",
    "    def encodes(self, toks):\n",
    "        return self.num(toks)\n",
    "    \n",
    "    def decodes(self, encoded):\n",
    "        return self.num.decode(encoded)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer(Transform):\n",
    "    def setups(self, items):\n",
    "        path = untar_data(URLs.IMDB)\n",
    "        self.tok = Tokenizer.from_folder(path)\n",
    "        self.tok.setup(items)\n",
    "        \n",
    "    def encodes(self, txts):\n",
    "        return self.tok(txts)\n",
    "    \n",
    "    def decodes(self, encoded):\n",
    "        return self.tok.decode(encoded)\n",
    "            \n",
    "class MyNumerizer(Transform):\n",
    "    def setups(self, items):\n",
    "        self.num = Numericalize()\n",
    "        #print(items)\n",
    "        self.num.setup(items)\n",
    "        self.vocab = self.num.vocab\n",
    "\n",
    "    def encodes(self, toks):\n",
    "        return self.num(toks)\n",
    "    \n",
    "    def decodes(self, encoded):\n",
    "        return self.num.decode(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subword Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer(Transform):\n",
    "    def setups(self, items):\n",
    "        self.tok = SubwordTokenizer(vocab_sz=1000)\n",
    "        self.tok.setup(items)\n",
    "        \n",
    "    def encodes(self, txts):\n",
    "        toks = self.tok(txts)\n",
    "        tokenized_sentences = [[tok for tok in gen] for gen in toks]\n",
    "        flattened_list = [item for sublist in tokenized_sentences for item in sublist if item]\n",
    "        return flattened_list\n",
    "    \n",
    "    def decodes(self, encoded):\n",
    "        decoded_values = TitledStr(''.join(encoded))\n",
    "        return  decoded_values\n",
    "            \n",
    "class MyNumerizer(Transform):\n",
    "    def setups(self, items):\n",
    "        self.num = Numericalize()\n",
    "        self.num.setup(items)\n",
    "        self.vocab = self.num.vocab\n",
    "        \n",
    "\n",
    "    def encodes(self, toks):\n",
    "        return self.num(toks)\n",
    "    \n",
    "    def decodes(self, encoded):\n",
    "        return self.num.decode(encoded)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=tmp/texts.out --vocab_size=1000 --model_prefix=tmp/spm --character_coverage=0.99999 --model_type=unigram --unk_id=9 --pad_id=-1 --bos_id=-1 --eos_id=-1 --minloglevel=2 --user_defined_symbols=▁xxunk,▁xxpad,▁xxbos,▁xxeos,▁xxfld,▁xxrep,▁xxwrep,▁xxup,▁xxmaj --hard_vocab_limit=false\n"
     ]
    }
   ],
   "source": [
    "limit = 200\n",
    "txt200 = txts[:limit]\n",
    "tokn = MyTokenizer()\n",
    "tokn.setup(txt200)\n",
    "\n",
    "toks = txt200.map(tokn)\n",
    "\n",
    "num = MyNumerizer()\n",
    "num.setup(toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's about jealousy, it's about racism, it's about manipulation, but the underlying message is love. Geoffrey Sax tried to pull off Shakespeare's Othello, by bringing it to modern day context. However, the actors were not convincing enough to pull this off. There were extra bodies to help put everything in to perspective, however, John Othello, played by Eamonn Walker, over reacted a lot in this film, causing for the down fall of Keeley Hawes, Dessie Brabant, eventually ending in Dessie's death. <br /><br />Ben Jago, played by Christopher Eccleston, was seen as the main character in the film. He didn't give enough evidence for Dessie to be cheating on Othello, with Michael Cass, played by Richard Coyle. Instead he just played a friend to all and gave one reason as to why she \"was\" cheating. In the play, it took a lot more convincing from Iago to make Othello even suspect anything. This change made the movie more about rage for the wrong reasons, than what the book was based off of. However, the movie did have a few good points. It turned the army scenes into more a racist group toward blacks, where Othello is the main chief of the police squad. These scenes are made believable by the raging crowds, and burning fires. You are able to sense the amount of racism in the movie, more so than you can in the book. This book plays up the modern day scenes by making it much easier to understand, than the Shakespearian times it was written in. In the play Iago (Jago) gets tortured at the end, but in the film he gets his satisfaction, and gets Othello's position. He never gets what he deserves and is never caught for telling the lie to Othello until it is too late. I saw this as a downfall in the movie, because I feel that the villain is granted his treasure of the promotion out of lying, and in the book, he is found out by Rodrigo. Overall, the movie could have done a better job based on the play than what it did. I feel that the director of the movie left out some of the most important parts of the play that were mentioned or there to make the play flow, or make it more of a tragedy. I would say that you should read the book first, in order to understand all of the events that happened in the movie, otherwise you may find yourself lost, and confused.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁N▁o▁t▁t▁o▁o▁g▁o▁o▁d▁a▁m▁o▁v▁i▁e▁.▁S▁u▁r▁e▁,▁i▁t▁c▁o▁n▁t▁a▁i▁n▁s▁a▁c▁t▁i▁o▁n▁,▁b▁u▁t</td>\n",
       "      <td>▁o▁t▁t▁o▁o▁g▁o▁o▁d▁a▁m▁o▁v▁i▁e▁.▁S▁u▁r▁e▁,▁i▁t▁c▁o▁n▁t▁a▁i▁n▁s▁a▁c▁t▁i▁o▁n▁,▁b▁u▁t▁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁e▁e▁l▁i▁n▁g▁t▁h▁e▁a▁u▁d▁i▁e▁n▁c▁e▁w▁a▁s▁b▁e▁i▁n▁g▁p▁a▁t▁r▁o▁n▁i▁z▁e▁d▁-▁-▁t▁h▁e▁r▁e▁w</td>\n",
       "      <td>e▁e▁l▁i▁n▁g▁t▁h▁e▁a▁u▁d▁i▁e▁n▁c▁e▁w▁a▁s▁b▁e▁i▁n▁g▁p▁a▁t▁r▁o▁n▁i▁z▁e▁d▁-▁-▁t▁h▁e▁r▁e▁w▁a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfms = [[tokn, num]]\n",
    "dsets = Datasets(txts[:limit], tfms)\n",
    "dls = dsets.dataloaders(dl_type=LMDataLoader)\n",
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained('bert-base-uncased')\n",
    "\n",
    "config.vocab_size = len(dls.vocab)\n",
    "config.num_labels = len(dls.vocab)\n",
    "config.hidden_size = 395\n",
    "config.num_hidden_layers = 12\n",
    "config.num_attention_heads = 5\n",
    "config.max_position_embeddings = 512\n",
    "transformer = ShellTransformer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.989378</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>15:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/University/GNN/project/transformer_env/lib/python3.9/site-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    }
   ],
   "source": [
    "model = transformer\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "dls.to(device)\n",
    "\n",
    "\n",
    "learn = Learner(\n",
    "    dls, \n",
    "    model, \n",
    "    loss_func=CrossEntropyLossFlat(), \n",
    "    metrics=[accuracy]\n",
    ")\n",
    "\n",
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_118109/226739576.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(token_ids).unsqueeze(0).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁I ▁ l ▁ i ▁ k ▁ e ▁ d ▁ t ▁ h ▁ e ▁ m ▁ o ▁v ▁ i ▁ e ▁ e ▁ e ▁ e ▁ e ▁ e ▁ s ▁ e ▁ e ▁ s ▁ e\n"
     ]
    }
   ],
   "source": [
    "# Define a function for text generation\n",
    "def generate_text(model, token_ids, max_length=20):\n",
    "    token_ids = token_ids\n",
    "    input_ids = torch.tensor(token_ids).unsqueeze(0).to(device)  \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            outputs = model(input_ids)\n",
    "            logits = outputs[:, -1, :]  \n",
    "            next_token_id = torch.argmax(logits, dim=-1)\n",
    "            token_ids = torch.cat((token_ids, next_token_id),dim=0)\n",
    "            input_ids = torch.cat([input_ids, next_token_id.unsqueeze(0).to(device)], dim=-1)\n",
    "    return token_ids\n",
    "\n",
    "def decode_tokens(numerized_tokens, vocab):\n",
    "    generated_test = [vocab[token] for token in numerized_tokens]\n",
    "    return ' '.join(generated_test)\n",
    "\n",
    "\n",
    "pipe = Pipeline([tokn,num])\n",
    "\n",
    "example_sentence = \"I liked the movie \"\n",
    "start_text_ids = pipe(example_sentence)\n",
    "generated_ids = generate_text(learn.model, start_text_ids)\n",
    "vocab = dls.vocab\n",
    "     \n",
    "print(decode_tokens(generated_ids,vocab))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
