{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf889c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from transformers import AutoTokenizer\n",
    "model_ckpt = \"bert-base-uncased\"\n",
    "text = \"time flies like an arrow\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa610da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2051, 10029,  2066,  2019,  8612]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c36021ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 2051, 10029,  2066,  2019,  8612]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c9a3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "token_emb = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "token_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5868236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522 768\n"
     ]
    }
   ],
   "source": [
    "print(config.vocab_size, config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c212e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 12 64\n"
     ]
    }
   ],
   "source": [
    "print(config.hidden_size, config.num_attention_heads, config.hidden_size//config.num_attention_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a46392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2051, 10029,  2066,  2019,  8612]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2babaca5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token_emb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tok_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtoken_emb\u001b[49m(tok_id)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'token_emb' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tok_id = torch.tensor(1)\n",
    "\n",
    "token_emb(tok_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a4724b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\\n\\n    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\\n\\n    On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\\n\\n    Args:\\n        in_features: size of each input sample\\n        out_features: size of each output sample\\n        bias: If set to ``False``, the layer will not learn an additive bias.\\n            Default: ``True``\\n\\n    Shape:\\n        - Input: :math:`(*, H_{in})` where :math:`*` means any number of\\n          dimensions including none and :math:`H_{in} = \\\\text{in\\\\_features}`.\\n        - Output: :math:`(*, H_{out})` where all but the last dimension\\n          are the same shape as the input and :math:`H_{out} = \\\\text{out\\\\_features}`.\\n\\n    Attributes:\\n        weight: the learnable weights of the module of shape\\n            :math:`(\\\\text{out\\\\_features}, \\\\text{in\\\\_features})`. The values are\\n            initialized from :math:`\\\\mathcal{U}(-\\\\sqrt{k}, \\\\sqrt{k})`, where\\n            :math:`k = \\\\frac{1}{\\\\text{in\\\\_features}}`\\n        bias:   the learnable bias of the module of shape :math:`(\\\\text{out\\\\_features})`.\\n                If :attr:`bias` is ``True``, the values are initialized from\\n                :math:`\\\\mathcal{U}(-\\\\sqrt{k}, \\\\sqrt{k})` where\\n                :math:`k = \\\\frac{1}{\\\\text{in\\\\_features}}`\\n\\n    Examples::\\n\\n        >>> m = nn.Linear(20, 30)\\n        >>> input = torch.randn(128, 20)\\n        >>> output = m(input)\\n        >>> print(output.size())\\n        torch.Size([128, 30])\\n    '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fd6931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 30])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 30])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Linear(20, 30)\n",
    "input = torch.randn(128, 20)\n",
    "output = m(input)\n",
    "print(output.size())\n",
    "torch.Size([128, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0b2d74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Linear(2, 3)\n",
    "input = torch.randn(2, 2)\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922d8a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0501, -0.4787],\n",
       "        [-0.5007, -2.2117]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ee106d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=3, bias=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "919496a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4911,  0.3192,  0.0080],\n",
       "        [-1.3763,  0.9012, -0.0895]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ca5e05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - fastai\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03e28be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mall\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming dls_lm is already defined\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load pre-trained language model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m learn \u001b[38;5;241m=\u001b[39m language_model_learner(dls_lm, AWD_LSTM, drop_mult\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai'"
     ]
    }
   ],
   "source": [
    "from fastai.text.all import *\n",
    "\n",
    "# Assuming dls_lm is already defined\n",
    "\n",
    "# Load pre-trained language model\n",
    "learn = language_model_learner(dls_lm, AWD_LSTM, drop_mult=0.3)\n",
    "\n",
    "# Get embeddings for a batch of text data\n",
    "text = \"This is a test sentence.\"\n",
    "tokens = learn.dls.train_ds.tokenizer([text])[0]  # Tokenize the text\n",
    "embeddings = learn.model[0].module.encoder(tokens[None])  # Pass tokens through the model's embedding layer to get embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec647c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_ai",
   "language": "python",
   "name": "gen_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
