{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d49f2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977153f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746c00e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b1231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_imdb = partial(get_text_files,folders=['train','test','unsup'])\n",
    "\n",
    "dls_lm = DataBlock(\n",
    "    blocks=TextBlock.from_folder(path, is_lm=True),\n",
    "    get_items=get_imdb, splitter=RandomSplitter(0.1)\n",
    ").dataloaders(path, path=path, bs=128, seq_len=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba310616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60008"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls_lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "981dea99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'xxup',\n",
       " 'xxmaj',\n",
       " 'the']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_lm.vocab[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffc80ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fastai.data.core.DataLoaders object at 0x778df6a40880>\n"
     ]
    }
   ],
   "source": [
    "print(dls_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4194ca80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos i used to love xxmaj sabrina xxmaj the xxmaj teenage xxmaj witch and have seen every single episode . i remember when i used to sit at 6 pm every night and wait for it to come on xxmaj nickelodeon , however when xxmaj sabrina left high school the show began to go downhill . xxmaj the best series has to be when she was friends with xxmaj valerie ( i 'm not sure which one that is )</td>\n",
       "      <td>i used to love xxmaj sabrina xxmaj the xxmaj teenage xxmaj witch and have seen every single episode . i remember when i used to sit at 6 pm every night and wait for it to come on xxmaj nickelodeon , however when xxmaj sabrina left high school the show began to go downhill . xxmaj the best series has to be when she was friends with xxmaj valerie ( i 'm not sure which one that is ) .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>problems to survive they own destruction . xxmaj as i said before , the show began great , all was almost perfect , including characters like xxmaj da'an , the original xxmaj da'an was a big mystery because he seems to be a nice creature but at the same time he has his own evil plans manipulating some people in earth . xxmaj soon came xxmaj xxunk who was n't bad but … mark the beginning of the fall of</td>\n",
       "      <td>to survive they own destruction . xxmaj as i said before , the show began great , all was almost perfect , including characters like xxmaj da'an , the original xxmaj da'an was a big mystery because he seems to be a nice creature but at the same time he has his own evil plans manipulating some people in earth . xxmaj soon came xxmaj xxunk who was n't bad but … mark the beginning of the fall of this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>have changed since now most xxup tv sitcoms are about young people and the industry avoids most shows about middle - aged people like the plague ! ) \\n\\n xxmaj subsequently , one of the young stars of \" love in the xxmaj happy xxmaj days \" , a child actor from \" the xxmaj andy xxmaj griffith xxmaj show \" named xxmaj ron xxmaj howard , got the chance to star in a film about young people taking place</td>\n",
       "      <td>changed since now most xxup tv sitcoms are about young people and the industry avoids most shows about middle - aged people like the plague ! ) \\n\\n xxmaj subsequently , one of the young stars of \" love in the xxmaj happy xxmaj days \" , a child actor from \" the xxmaj andy xxmaj griffith xxmaj show \" named xxmaj ron xxmaj howard , got the chance to star in a film about young people taking place in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>face this opinion in a discussion and if you are willing to really look into the art of xxunk you would have to \" surrender \" . xxbos xxmaj this cordial comedy confronts a few bizarre characters . xxmaj especially , of course , the two leading characters . xxmaj jack xxmaj lemmon plays xxmaj felix , a hypochondriac whose wife lost him because she could n't stand his cleaning and cooking attacks any longer . xxmaj so he tries</td>\n",
       "      <td>this opinion in a discussion and if you are willing to really look into the art of xxunk you would have to \" surrender \" . xxbos xxmaj this cordial comedy confronts a few bizarre characters . xxmaj especially , of course , the two leading characters . xxmaj jack xxmaj lemmon plays xxmaj felix , a hypochondriac whose wife lost him because she could n't stand his cleaning and cooking attacks any longer . xxmaj so he tries to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and when the accents was so poor , this equaled in very low performance , and i sometimes felt that i was watching xxmaj swedish xxmaj big xxmaj brother ",
       "▁ i think this is because xxmaj swedish actors has not yet understood that acting is with whole body , eye moves , body - language , etc , not just standing there like a jukebox and saying your lines one after other . xxmaj the kids acting was horrible ,</td>\n",
       "      <td>when the accents was so poor , this equaled in very low performance , and i sometimes felt that i was watching xxmaj swedish xxmaj big xxmaj brother ",
       "▁ i think this is because xxmaj swedish actors has not yet understood that acting is with whole body , eye moves , body - language , etc , not just standing there like a jukebox and saying your lines one after other . xxmaj the kids acting was horrible , i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>recorded his numbers ( spectacularly ) for that release . xxmaj brock xxmaj peters ' bass / baritone is extraordinary and xxmaj pearl xxmaj bailey is her own unique self . xxmaj diahann xxmaj carroll , although a singer of fine note , has the small role of xxmaj clara which required a high soprano , so old reliable xxmaj marni xxmaj nixon dubbed her singing . \\n\\n xxmaj the xxmaj gershwin xxmaj estate hates the film and refuses to</td>\n",
       "      <td>his numbers ( spectacularly ) for that release . xxmaj brock xxmaj peters ' bass / baritone is extraordinary and xxmaj pearl xxmaj bailey is her own unique self . xxmaj diahann xxmaj carroll , although a singer of fine note , has the small role of xxmaj clara which required a high soprano , so old reliable xxmaj marni xxmaj nixon dubbed her singing . \\n\\n xxmaj the xxmaj gershwin xxmaj estate hates the film and refuses to grant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the classics or something with a spine and an arc to it . xxmaj donate this to xxup pbs . xxbos xxmaj the best scene of \" the xxmaj people xxmaj across xxmaj the xxmaj lake \" is the genuinely creepy , nightly opening - scene featuring a house , a murder &amp; a lake . xxmaj after that , it 's pretty much downhill from there on as far as the horror is concerned . a family ( mom</td>\n",
       "      <td>classics or something with a spine and an arc to it . xxmaj donate this to xxup pbs . xxbos xxmaj the best scene of \" the xxmaj people xxmaj across xxmaj the xxmaj lake \" is the genuinely creepy , nightly opening - scene featuring a house , a murder &amp; a lake . xxmaj after that , it 's pretty much downhill from there on as far as the horror is concerned . a family ( mom ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>basic lessons in acting . xxmaj seema xxmaj biswas , xxmaj xxunk xxmaj yadav and xxmaj xxunk xxmaj xxunk have saved the movie as much as they can . xxmaj the kid had done an outstanding job . xxmaj the editing and the flow of the movie is also not something you would have expected from xxmaj deepa . xxmaj great subject , sends out a strong message about a practice which is still pretty rampant in rural xxmaj india</td>\n",
       "      <td>lessons in acting . xxmaj seema xxmaj biswas , xxmaj xxunk xxmaj yadav and xxmaj xxunk xxmaj xxunk have saved the movie as much as they can . xxmaj the kid had done an outstanding job . xxmaj the editing and the flow of the movie is also not something you would have expected from xxmaj deepa . xxmaj great subject , sends out a strong message about a practice which is still pretty rampant in rural xxmaj india but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>but when their horse returns without papa , xxmaj belle sets out to find the awful truth in an enchanted castle . \\n\\n xxmaj you can see that so much time and care was spent in drawing this masterpiece . i can not think of many other movies that show such meticulous background and animation . xxmaj that such effort is woven effortlessly into its songs that make xxmaj beauty and the xxmaj beast the timeless classic xxmaj disney rightfully</td>\n",
       "      <td>when their horse returns without papa , xxmaj belle sets out to find the awful truth in an enchanted castle . \\n\\n xxmaj you can see that so much time and care was spent in drawing this masterpiece . i can not think of many other movies that show such meticulous background and animation . xxmaj that such effort is woven effortlessly into its songs that make xxmaj beauty and the xxmaj beast the timeless classic xxmaj disney rightfully lauds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99cd8292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value):\n",
    "    dim_k = query.size(-1)\n",
    "    scores = torch.bmm(query, key.transpose(1, 2)) / np.sqrt(dim_k)\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return torch.bmm(weights, value)\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, embed_dim, head_dim):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(embed_dim, head_dim)\n",
    "        self.k = nn.Linear(embed_dim, head_dim)\n",
    "        self.v = nn.Linear(embed_dim, head_dim)\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        attn_outputs = scaled_dot_product_attention(\n",
    "            self.q(hidden_state), self.k(hidden_state), self.v(hidden_state))\n",
    "        return attn_outputs\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        embed_dim = embed_dim\n",
    "        num_heads = num_heads\n",
    "        head_dim = embed_dim // num_heads\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.heads = nn.ModuleList(\n",
    "            [AttentionHead(embed_dim, head_dim) for _ in range(num_heads)]\n",
    "        )\n",
    "        self.output_linear = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        #print(hidden_state)\n",
    "        embed_state = self.embedding(hidden_state)\n",
    "        #print(embed_state)\n",
    "        x = torch.cat([h(embed_state) for h in self.heads], dim=-1)\n",
    "        #print(\"1\")\n",
    "        x = self.output_linear(x)\n",
    "        print(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f97c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='8' class='' max='2629' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.30% [8/2629 00:58&lt;5:19:43 10.9895]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0285,  0.0580, -0.0790,  ...,  0.0286, -0.2310,  0.0477],\n",
      "         [ 0.0188,  0.0604, -0.0434,  ...,  0.0793, -0.1644,  0.0219],\n",
      "         [-0.0388,  0.0452, -0.0554,  ...,  0.0473, -0.2214,  0.0319],\n",
      "         ...,\n",
      "         [-0.0038,  0.0499, -0.0140,  ...,  0.0348, -0.1784,  0.0079],\n",
      "         [-0.0396,  0.0488, -0.0903,  ...,  0.0321, -0.2058,  0.0352],\n",
      "         [ 0.0019,  0.0836, -0.0469,  ...,  0.0432, -0.2038,  0.0524]],\n",
      "\n",
      "        [[-0.0167,  0.0644, -0.0180,  ...,  0.0677, -0.1205,  0.0559],\n",
      "         [ 0.0192,  0.0097, -0.0373,  ...,  0.0223, -0.1233,  0.0263],\n",
      "         [-0.0225,  0.0499, -0.0296,  ..., -0.0113, -0.1567,  0.0819],\n",
      "         ...,\n",
      "         [-0.0249,  0.0673, -0.0459,  ..., -0.0296, -0.1457,  0.0724],\n",
      "         [-0.0362, -0.0026, -0.0464,  ...,  0.0763, -0.1917,  0.0577],\n",
      "         [-0.0167,  0.0644, -0.0180,  ...,  0.0677, -0.1205,  0.0559]],\n",
      "\n",
      "        [[-0.0333,  0.1203, -0.0801,  ...,  0.1295, -0.0743, -0.0215],\n",
      "         [-0.0087,  0.1030, -0.0722,  ...,  0.1176, -0.0387, -0.0516],\n",
      "         [ 0.0096,  0.0893, -0.0808,  ...,  0.1382, -0.0154, -0.0257],\n",
      "         ...,\n",
      "         [ 0.0251,  0.0950, -0.0831,  ...,  0.1167, -0.0470, -0.0556],\n",
      "         [-0.0007,  0.0915, -0.1440,  ...,  0.1082, -0.0605, -0.0531],\n",
      "         [ 0.0277,  0.0360, -0.0915,  ...,  0.1297, -0.0125, -0.0106]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0288, -0.0198, -0.1247,  ...,  0.0335, -0.1214,  0.0095],\n",
      "         [-0.0057, -0.0218, -0.1244,  ...,  0.0372, -0.1627, -0.0174],\n",
      "         [ 0.0352, -0.0363, -0.1457,  ...,  0.0386, -0.1164, -0.0200],\n",
      "         ...,\n",
      "         [ 0.0041, -0.0718, -0.1471,  ...,  0.0488, -0.0904, -0.0318],\n",
      "         [-0.0021, -0.0297, -0.1387,  ...,  0.0302, -0.1330,  0.0019],\n",
      "         [ 0.0186, -0.0089, -0.1402,  ...,  0.0419, -0.1054, -0.0175]],\n",
      "\n",
      "        [[-0.0009,  0.0641, -0.0675,  ...,  0.0389, -0.1034,  0.0287],\n",
      "         [-0.0167,  0.0174, -0.0925,  ...,  0.0226, -0.1532,  0.0449],\n",
      "         [-0.0381,  0.0685, -0.0824,  ...,  0.0298, -0.1141,  0.0121],\n",
      "         ...,\n",
      "         [-0.0332,  0.0368, -0.0725,  ...,  0.0382, -0.1120,  0.0475],\n",
      "         [-0.0165,  0.0556, -0.0451,  ...,  0.0055, -0.0904,  0.0409],\n",
      "         [-0.0207,  0.0371, -0.0700,  ...,  0.0497, -0.0870, -0.0460]],\n",
      "\n",
      "        [[ 0.0605,  0.0108, -0.0017,  ...,  0.0074, -0.1609, -0.0115],\n",
      "         [ 0.0205,  0.0213, -0.0289,  ...,  0.0068, -0.1618,  0.0203],\n",
      "         [ 0.0227, -0.0135,  0.0064,  ...,  0.0042, -0.1651, -0.0230],\n",
      "         ...,\n",
      "         [ 0.0019, -0.0335, -0.0064,  ...,  0.0291, -0.1375, -0.0247],\n",
      "         [ 0.0472,  0.0013,  0.0166,  ...,  0.0194, -0.1337, -0.0217],\n",
      "         [ 0.0472, -0.0144, -0.0035,  ...,  0.0003, -0.1563, -0.0066]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0349,  0.0174,  0.0497,  ..., -0.0675, -0.1320,  0.0364],\n",
      "         [-0.0260, -0.0328,  0.0311,  ..., -0.0483, -0.1778,  0.0411],\n",
      "         [-0.0406,  0.0013,  0.0239,  ..., -0.0439, -0.1977,  0.0174],\n",
      "         ...,\n",
      "         [-0.0263, -0.0006,  0.0024,  ..., -0.0569, -0.2005,  0.0344],\n",
      "         [-0.0245,  0.0059,  0.0349,  ..., -0.0252, -0.1659,  0.0272],\n",
      "         [-0.0759,  0.0195,  0.0160,  ..., -0.0464, -0.2023,  0.0641]],\n",
      "\n",
      "        [[ 0.0450,  0.0061, -0.0740,  ...,  0.0660, -0.1048,  0.0780],\n",
      "         [-0.0045, -0.0338, -0.0816,  ...,  0.0767, -0.1023,  0.0580],\n",
      "         [ 0.0318,  0.0422, -0.0789,  ...,  0.0721, -0.0950,  0.0804],\n",
      "         ...,\n",
      "         [ 0.0446,  0.0048, -0.0639,  ...,  0.0992, -0.0851,  0.0647],\n",
      "         [-0.0014, -0.0240, -0.0742,  ...,  0.0886, -0.1228,  0.0568],\n",
      "         [ 0.0450,  0.0061, -0.0740,  ...,  0.0660, -0.1048,  0.0780]],\n",
      "\n",
      "        [[ 0.0192,  0.0578, -0.0978,  ...,  0.0640, -0.0391, -0.0196],\n",
      "         [-0.0097,  0.0617, -0.1106,  ...,  0.0439, -0.1067,  0.0177],\n",
      "         [ 0.0061,  0.0701, -0.1300,  ...,  0.0671, -0.0370, -0.0364],\n",
      "         ...,\n",
      "         [ 0.0190,  0.0698, -0.1019,  ...,  0.0651, -0.0703, -0.0117],\n",
      "         [-0.0284,  0.0774, -0.0892,  ...,  0.0523, -0.0754,  0.0004],\n",
      "         [ 0.0035,  0.0604, -0.1031,  ...,  0.0215, -0.0814,  0.0056]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128,  0.0182, -0.1590,  ...,  0.0164, -0.1262,  0.0057],\n",
      "         [ 0.0010,  0.0202, -0.1202,  ...,  0.0027, -0.1554,  0.0277],\n",
      "         [-0.0037, -0.0174, -0.1318,  ...,  0.0562, -0.1281, -0.0193],\n",
      "         ...,\n",
      "         [-0.0185, -0.0026, -0.1339,  ...,  0.0252, -0.1076,  0.0238],\n",
      "         [ 0.0102, -0.0256, -0.1207,  ...,  0.0234, -0.1344,  0.0078],\n",
      "         [-0.0483, -0.0356, -0.1336,  ...,  0.0365, -0.1180, -0.0110]],\n",
      "\n",
      "        [[ 0.0231,  0.0813, -0.0879,  ...,  0.0231, -0.1602,  0.0302],\n",
      "         [ 0.0054,  0.0591, -0.0790,  ..., -0.0018, -0.1683,  0.0299],\n",
      "         [ 0.0112,  0.0932, -0.0468,  ...,  0.0507, -0.1403,  0.0179],\n",
      "         ...,\n",
      "         [ 0.0219,  0.0847, -0.0662,  ...,  0.0310, -0.1383,  0.0180],\n",
      "         [ 0.0091,  0.0685, -0.0926,  ...,  0.0517, -0.1849,  0.0069],\n",
      "         [ 0.0233,  0.0513, -0.0870,  ...,  0.0377, -0.1733,  0.0263]],\n",
      "\n",
      "        [[-0.0008,  0.0450, -0.0455,  ...,  0.0819, -0.0967, -0.0127],\n",
      "         [-0.0177,  0.0657, -0.0688,  ...,  0.0582, -0.0942, -0.0446],\n",
      "         [-0.0644,  0.0588, -0.0808,  ...,  0.0406, -0.0915, -0.0204],\n",
      "         ...,\n",
      "         [-0.0316,  0.0369, -0.0444,  ...,  0.0573, -0.0861, -0.0156],\n",
      "         [-0.0180,  0.0192, -0.0956,  ...,  0.0579, -0.1077, -0.0155],\n",
      "         [-0.0203,  0.0573, -0.0699,  ...,  0.0577, -0.0868, -0.0215]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-2.3081e-02, -9.7432e-03,  3.3460e-04,  ...,  1.0719e-01,\n",
      "          -1.5565e-01, -1.8972e-02],\n",
      "         [-9.9534e-03,  3.6123e-03, -6.6390e-03,  ...,  8.3175e-02,\n",
      "          -1.6689e-01,  1.3221e-02],\n",
      "         [ 2.8839e-04, -1.7774e-02,  2.1118e-04,  ...,  1.0371e-01,\n",
      "          -1.8484e-01,  1.3437e-02],\n",
      "         ...,\n",
      "         [ 1.8021e-02, -2.0081e-02,  1.8633e-02,  ...,  1.3453e-01,\n",
      "          -1.6765e-01, -4.1005e-03],\n",
      "         [ 3.0738e-03, -2.3239e-02, -4.7960e-03,  ...,  7.3927e-02,\n",
      "          -1.7872e-01,  7.2505e-03],\n",
      "         [-1.6425e-03, -3.5838e-02,  7.5642e-04,  ...,  7.4227e-02,\n",
      "          -2.1235e-01, -8.5579e-03]],\n",
      "\n",
      "        [[-4.3777e-02,  5.0807e-02, -8.0277e-02,  ...,  6.9809e-02,\n",
      "          -1.3204e-01,  1.5849e-02],\n",
      "         [-2.0743e-02,  5.9083e-02, -1.3358e-01,  ...,  2.9372e-02,\n",
      "          -1.1937e-01,  8.4336e-03],\n",
      "         [-6.7401e-02,  8.5067e-03, -8.9494e-02,  ...,  2.5297e-02,\n",
      "          -1.1375e-01,  2.6358e-03],\n",
      "         ...,\n",
      "         [-3.0637e-02,  2.0602e-02, -1.2418e-01,  ...,  2.6920e-02,\n",
      "          -1.1683e-01,  1.5314e-03],\n",
      "         [-1.1051e-02,  7.2597e-02, -7.2032e-02,  ...,  4.8659e-02,\n",
      "          -1.1914e-01,  1.8454e-02],\n",
      "         [-6.7859e-02,  6.6864e-02, -1.2651e-01,  ...,  2.7307e-02,\n",
      "          -1.2681e-01,  2.7747e-02]],\n",
      "\n",
      "        [[ 1.9940e-03,  8.5322e-02, -5.6292e-02,  ..., -6.3111e-03,\n",
      "          -8.2862e-02,  7.1690e-02],\n",
      "         [-2.6982e-02,  7.4687e-02, -2.4266e-02,  ...,  7.8800e-02,\n",
      "          -9.1359e-02,  2.2611e-02],\n",
      "         [ 9.6839e-03,  5.4495e-02, -1.3499e-02,  ...,  6.6471e-02,\n",
      "          -5.7161e-02,  2.3641e-02],\n",
      "         ...,\n",
      "         [-3.2917e-02,  7.5737e-02, -9.4882e-03,  ...,  6.2471e-02,\n",
      "          -1.1742e-01,  5.4489e-02],\n",
      "         [-3.2350e-02,  1.1974e-01, -6.5085e-02,  ...,  3.5987e-02,\n",
      "          -9.2726e-02,  5.1799e-02],\n",
      "         [-1.3845e-02,  6.7061e-02, -3.8958e-02,  ...,  2.0760e-02,\n",
      "          -6.6728e-02,  3.6897e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.0407e-02,  4.2244e-02, -1.1031e-01,  ...,  3.7399e-02,\n",
      "          -1.1384e-01, -4.1475e-03],\n",
      "         [ 2.1415e-02,  1.6211e-02, -1.1973e-01,  ...,  3.2163e-02,\n",
      "          -1.4674e-01, -1.5192e-03],\n",
      "         [ 6.0078e-02,  4.1440e-02, -1.0170e-01,  ...,  3.0769e-02,\n",
      "          -1.0589e-01, -1.1759e-02],\n",
      "         ...,\n",
      "         [ 7.9333e-02,  3.4543e-02, -9.0109e-02,  ...,  5.2708e-02,\n",
      "          -1.3592e-01, -1.8912e-03],\n",
      "         [ 2.2947e-02,  4.1313e-02, -1.1677e-01,  ..., -3.6762e-03,\n",
      "          -1.9351e-01,  2.5162e-03],\n",
      "         [ 5.4010e-02,  1.5055e-02, -1.2249e-01,  ...,  3.3963e-02,\n",
      "          -1.1685e-01, -5.1661e-02]],\n",
      "\n",
      "        [[-4.8820e-02,  5.1103e-02, -9.1456e-02,  ..., -6.8937e-03,\n",
      "          -3.8808e-02,  4.4592e-03],\n",
      "         [-2.9559e-02,  5.0048e-02, -8.1593e-02,  ..., -1.9857e-02,\n",
      "          -7.0798e-02,  2.0369e-02],\n",
      "         [-1.5162e-02,  2.1129e-02, -1.0476e-01,  ...,  8.4180e-03,\n",
      "          -8.3996e-02, -6.3096e-03],\n",
      "         ...,\n",
      "         [-6.8600e-02,  2.3877e-02, -1.0350e-01,  ...,  4.8402e-02,\n",
      "          -7.3054e-02, -1.5166e-03],\n",
      "         [-1.5068e-02,  1.2169e-02, -7.9148e-02,  ...,  2.9833e-02,\n",
      "          -3.9232e-02, -6.6100e-03],\n",
      "         [-5.3405e-02,  3.9918e-03, -9.7479e-02,  ...,  4.4943e-03,\n",
      "          -4.6530e-02,  2.7306e-02]],\n",
      "\n",
      "        [[ 1.0367e-01, -4.1913e-02,  1.6008e-02,  ...,  3.0994e-02,\n",
      "          -9.8227e-02,  3.5210e-02],\n",
      "         [ 9.5698e-02, -2.8888e-02, -2.2470e-02,  ...,  3.3804e-02,\n",
      "          -1.3117e-01,  1.9276e-02],\n",
      "         [ 1.3232e-01, -3.7942e-02,  2.2010e-02,  ...,  3.5082e-02,\n",
      "          -1.1253e-01,  3.4464e-02],\n",
      "         ...,\n",
      "         [ 1.1423e-01, -1.7853e-02,  1.8920e-02,  ...,  2.7690e-02,\n",
      "          -9.8984e-02,  4.1848e-02],\n",
      "         [ 8.1088e-02, -1.5126e-02,  1.0716e-02,  ...,  2.6712e-03,\n",
      "          -1.3512e-01,  4.1511e-02],\n",
      "         [ 1.1795e-01, -4.7673e-02,  1.5307e-02,  ...,  2.8282e-03,\n",
      "          -1.1191e-01,  2.7455e-02]]], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0271,  0.0085, -0.1118,  ...,  0.0740, -0.0515, -0.0342],\n",
      "         [-0.0331,  0.0293, -0.0969,  ...,  0.0877, -0.0111, -0.0356],\n",
      "         [-0.0073, -0.0325, -0.0941,  ...,  0.0781, -0.0434, -0.0731],\n",
      "         ...,\n",
      "         [-0.0265,  0.0131, -0.0855,  ...,  0.0789, -0.0647, -0.0294],\n",
      "         [-0.0322,  0.0041, -0.0920,  ...,  0.0409, -0.0540, -0.0059],\n",
      "         [-0.0220, -0.0254, -0.0779,  ...,  0.0894, -0.0767, -0.0489]],\n",
      "\n",
      "        [[ 0.0374,  0.0106, -0.0964,  ...,  0.1169, -0.0588, -0.0137],\n",
      "         [ 0.0085,  0.0387, -0.0900,  ...,  0.1208, -0.0946, -0.0004],\n",
      "         [ 0.0182, -0.0030, -0.0699,  ...,  0.1550, -0.1156, -0.0147],\n",
      "         ...,\n",
      "         [ 0.0185, -0.0186, -0.0713,  ...,  0.0864, -0.0846, -0.0240],\n",
      "         [ 0.0514,  0.0221, -0.0798,  ...,  0.1008, -0.0808,  0.0011],\n",
      "         [ 0.0089,  0.0171, -0.0629,  ...,  0.1039, -0.0847, -0.0095]],\n",
      "\n",
      "        [[ 0.0188, -0.0116, -0.0762,  ...,  0.0459, -0.0337,  0.0356],\n",
      "         [ 0.0695, -0.0349, -0.0790,  ...,  0.0833, -0.0526, -0.0037],\n",
      "         [ 0.0311,  0.0185, -0.0839,  ...,  0.0729, -0.0608,  0.0312],\n",
      "         ...,\n",
      "         [ 0.0080,  0.0062, -0.0928,  ...,  0.0608, -0.0606,  0.0116],\n",
      "         [-0.0069, -0.0256, -0.1092,  ...,  0.0116, -0.0630,  0.0604],\n",
      "         [ 0.0191, -0.0157, -0.0877,  ...,  0.0477, -0.0665,  0.0465]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0065, -0.0271, -0.0644,  ...,  0.1398, -0.1236, -0.0490],\n",
      "         [ 0.0366, -0.0401, -0.0565,  ...,  0.1303, -0.1571, -0.0186],\n",
      "         [ 0.0366, -0.0121, -0.0976,  ...,  0.1088, -0.1129, -0.0234],\n",
      "         ...,\n",
      "         [-0.0065, -0.0247, -0.0655,  ...,  0.1355, -0.1458, -0.0049],\n",
      "         [ 0.0042,  0.0055, -0.0953,  ...,  0.1306, -0.1494, -0.0211],\n",
      "         [ 0.0291, -0.0470, -0.0949,  ...,  0.1143, -0.1027, -0.0278]],\n",
      "\n",
      "        [[ 0.1096,  0.0322, -0.0586,  ...,  0.0157, -0.0287,  0.0666],\n",
      "         [ 0.1129,  0.0196, -0.0671,  ...,  0.0572, -0.0531,  0.0409],\n",
      "         [ 0.0917,  0.0070, -0.0585,  ...,  0.0563, -0.0507,  0.0404],\n",
      "         ...,\n",
      "         [ 0.0913, -0.0030, -0.0658,  ...,  0.0300, -0.0548,  0.0359],\n",
      "         [ 0.0699, -0.0327, -0.0541,  ...,  0.0251, -0.0561,  0.0515],\n",
      "         [ 0.0529, -0.0251, -0.0380,  ...,  0.0394, -0.0597,  0.0745]],\n",
      "\n",
      "        [[ 0.0025,  0.0672, -0.0732,  ...,  0.0542, -0.1659,  0.0437],\n",
      "         [-0.0188,  0.0669, -0.0728,  ...,  0.0352, -0.1661,  0.0385],\n",
      "         [ 0.0025,  0.0672, -0.0732,  ...,  0.0542, -0.1659,  0.0437],\n",
      "         ...,\n",
      "         [ 0.0176,  0.0499, -0.0665,  ...,  0.0020, -0.1544,  0.0547],\n",
      "         [-0.0299,  0.0907, -0.0900,  ...,  0.0067, -0.1541,  0.0711],\n",
      "         [-0.0482,  0.0680, -0.0770,  ...,  0.0350, -0.1876,  0.0140]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 2.0023e-02,  1.6698e-02, -2.8900e-02,  ...,  8.6704e-02,\n",
      "          -8.5656e-02, -1.5961e-02],\n",
      "         [ 6.0435e-03,  1.1240e-02, -6.9541e-02,  ...,  8.0107e-02,\n",
      "          -5.5704e-02,  4.5902e-03],\n",
      "         [ 3.7016e-02, -3.2745e-02, -4.9363e-02,  ...,  7.5358e-02,\n",
      "          -6.1050e-02, -2.0591e-02],\n",
      "         ...,\n",
      "         [-5.7665e-03,  5.3105e-03, -4.3076e-02,  ...,  8.7392e-02,\n",
      "          -6.7197e-02, -6.3270e-03],\n",
      "         [ 1.4397e-02, -1.1428e-02, -1.9414e-02,  ...,  9.7105e-02,\n",
      "          -5.0468e-02, -2.5697e-03],\n",
      "         [ 9.7482e-03,  1.9222e-02, -4.5855e-02,  ...,  8.6919e-02,\n",
      "          -5.2271e-02, -1.3420e-02]],\n",
      "\n",
      "        [[-2.2407e-02,  1.4458e-01, -9.6404e-02,  ...,  8.3427e-03,\n",
      "          -1.4115e-01,  6.0042e-03],\n",
      "         [-2.3180e-02,  9.2002e-02, -6.1668e-02,  ...,  5.7208e-02,\n",
      "          -7.4514e-02,  1.6735e-02],\n",
      "         [ 2.4073e-03,  1.0104e-01, -5.9061e-02,  ...,  4.9035e-02,\n",
      "          -7.0237e-02, -1.0686e-02],\n",
      "         ...,\n",
      "         [-1.2319e-02,  8.1361e-02, -7.8634e-02,  ...,  6.5000e-02,\n",
      "          -5.8942e-02, -2.2879e-02],\n",
      "         [-1.2968e-02,  1.0171e-01, -6.0251e-02,  ...,  4.7886e-02,\n",
      "          -9.5087e-02, -2.7111e-02],\n",
      "         [-1.0729e-02,  1.3158e-01, -6.4781e-02,  ...,  6.9927e-02,\n",
      "          -1.1141e-01,  2.2080e-03]],\n",
      "\n",
      "        [[-6.0710e-03,  5.7237e-02, -9.7523e-02,  ...,  4.0586e-02,\n",
      "          -1.1890e-01, -1.1868e-02],\n",
      "         [ 2.2593e-05,  4.4948e-02, -1.4202e-01,  ...,  3.4089e-02,\n",
      "          -1.2026e-01,  5.8424e-05],\n",
      "         [ 7.6633e-03,  5.6868e-02, -8.4865e-02,  ...,  5.3168e-02,\n",
      "          -7.5559e-02,  1.8175e-02],\n",
      "         ...,\n",
      "         [-8.6410e-03,  6.4385e-02, -9.9000e-02,  ...,  5.9488e-02,\n",
      "          -1.1906e-01,  1.8823e-02],\n",
      "         [ 7.6633e-03,  5.6868e-02, -8.4865e-02,  ...,  5.3168e-02,\n",
      "          -7.5559e-02,  1.8175e-02],\n",
      "         [ 2.6000e-02,  7.4751e-02, -1.3458e-01,  ..., -1.5119e-02,\n",
      "          -1.0913e-01,  4.1733e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.6746e-02,  1.9803e-02, -6.9856e-03,  ...,  2.5148e-02,\n",
      "          -1.0697e-01, -3.7294e-02],\n",
      "         [-4.2253e-02,  7.7834e-02, -1.8995e-02,  ...,  1.0534e-02,\n",
      "          -1.0158e-01, -1.5250e-02],\n",
      "         [-3.4303e-02,  3.9938e-02, -3.7631e-03,  ...,  1.7741e-02,\n",
      "          -1.1709e-01, -2.2421e-02],\n",
      "         ...,\n",
      "         [-3.9659e-02,  2.6861e-03, -1.5988e-02,  ...,  1.9559e-02,\n",
      "          -1.1162e-01, -1.8260e-02],\n",
      "         [-4.2984e-02,  3.4512e-02, -1.3038e-02,  ...,  1.4580e-02,\n",
      "          -1.0103e-01, -4.2461e-02],\n",
      "         [-3.1868e-02,  2.6208e-02, -1.5672e-02,  ...,  3.4126e-02,\n",
      "          -1.3388e-01, -4.0498e-02]],\n",
      "\n",
      "        [[ 2.9638e-03,  9.4806e-03, -5.6642e-02,  ...,  2.1248e-02,\n",
      "          -1.2780e-01, -1.4746e-02],\n",
      "         [-1.8773e-02,  1.9761e-02, -1.9584e-02,  ...,  1.3926e-02,\n",
      "          -1.2472e-01, -4.8186e-03],\n",
      "         [ 5.2339e-02,  1.6549e-02, -4.5840e-02,  ...,  3.6557e-02,\n",
      "          -1.1004e-01, -2.6012e-02],\n",
      "         ...,\n",
      "         [ 1.5612e-02,  2.3058e-02, -5.7506e-02,  ...,  2.1432e-02,\n",
      "          -1.1193e-01, -8.8616e-03],\n",
      "         [ 6.6354e-03,  2.6663e-02, -3.5727e-02,  ...,  3.2186e-02,\n",
      "          -1.1421e-01, -2.9039e-02],\n",
      "         [ 2.0431e-02, -2.1753e-03, -2.7824e-02,  ...,  4.0894e-02,\n",
      "          -1.0701e-01, -3.4799e-02]],\n",
      "\n",
      "        [[ 6.5381e-02,  5.1984e-02, -5.7911e-02,  ..., -2.4061e-02,\n",
      "          -1.6141e-01,  1.7716e-02],\n",
      "         [ 3.4469e-02,  7.0392e-02, -7.6714e-02,  ..., -2.4087e-02,\n",
      "          -1.3193e-01, -6.1392e-03],\n",
      "         [ 7.5253e-02,  3.2590e-02, -3.9530e-02,  ...,  2.7198e-02,\n",
      "          -1.3665e-01, -9.3755e-03],\n",
      "         ...,\n",
      "         [ 3.5482e-02,  2.1663e-02, -6.2491e-02,  ...,  1.3007e-02,\n",
      "          -1.4742e-01, -2.1429e-02],\n",
      "         [ 5.7918e-02,  4.8520e-02, -7.2754e-02,  ...,  3.0233e-03,\n",
      "          -1.4057e-01, -2.6046e-04],\n",
      "         [ 4.0911e-02,  3.4154e-02, -6.9283e-02,  ..., -1.3300e-02,\n",
      "          -1.7026e-01,  7.5323e-03]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-6.0651e-02,  7.3353e-02, -1.0979e-01,  ...,  9.2962e-04,\n",
      "          -2.9853e-02, -7.9266e-02],\n",
      "         [-7.8309e-02,  1.0220e-01, -1.0184e-01,  ...,  2.8182e-02,\n",
      "          -5.9228e-02, -6.2683e-02],\n",
      "         [-4.7210e-02,  6.4321e-02, -1.4607e-01,  ...,  3.6401e-02,\n",
      "          -5.6054e-02, -6.3092e-02],\n",
      "         ...,\n",
      "         [-7.4519e-02,  6.7435e-02, -1.2765e-01,  ...,  4.1058e-02,\n",
      "          -5.1512e-02, -8.9360e-02],\n",
      "         [-6.0651e-02,  7.3353e-02, -1.0979e-01,  ...,  9.2962e-04,\n",
      "          -2.9853e-02, -7.9266e-02],\n",
      "         [-5.8900e-02,  7.9886e-02, -1.2505e-01,  ...,  3.9837e-02,\n",
      "          -4.7909e-02, -8.4785e-02]],\n",
      "\n",
      "        [[ 3.1708e-02,  7.6783e-02, -8.8752e-02,  ...,  4.5810e-02,\n",
      "          -1.4140e-01, -2.2111e-02],\n",
      "         [-1.6898e-02,  1.0090e-01, -9.1946e-02,  ...,  6.3889e-02,\n",
      "          -1.5172e-01, -3.0674e-02],\n",
      "         [-2.9100e-02,  1.1955e-01, -9.9512e-02,  ...,  3.0379e-02,\n",
      "          -1.2967e-01, -2.1479e-02],\n",
      "         ...,\n",
      "         [ 1.4087e-03,  1.0214e-01, -1.4057e-01,  ...,  6.1102e-02,\n",
      "          -1.3666e-01, -2.3423e-02],\n",
      "         [-1.0524e-02,  5.7349e-02, -1.1406e-01,  ...,  1.6203e-02,\n",
      "          -1.1392e-01, -1.2112e-02],\n",
      "         [-5.3372e-03,  1.0647e-01, -1.2306e-01,  ...,  5.0756e-02,\n",
      "          -1.3702e-01, -2.9051e-02]],\n",
      "\n",
      "        [[-2.3120e-02,  4.2809e-02, -6.0355e-02,  ..., -9.8645e-03,\n",
      "          -1.7064e-02,  4.9702e-02],\n",
      "         [-3.2412e-02,  7.7701e-02, -7.9693e-02,  ...,  3.9422e-02,\n",
      "          -6.7322e-02,  6.4412e-02],\n",
      "         [-5.8732e-03,  5.9965e-02, -8.3688e-02,  ..., -1.0024e-02,\n",
      "          -4.6294e-02,  4.7784e-02],\n",
      "         ...,\n",
      "         [ 1.1491e-02,  3.1726e-02, -5.7786e-02,  ...,  1.6338e-02,\n",
      "          -4.2356e-02,  3.6569e-02],\n",
      "         [-4.0494e-02,  7.4597e-02, -5.7741e-02,  ...,  3.9790e-02,\n",
      "          -5.2341e-02,  5.1993e-02],\n",
      "         [-7.4223e-03,  8.7838e-02, -1.0031e-01,  ..., -1.7028e-02,\n",
      "          -9.6200e-02,  6.9362e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.6752e-02,  1.7742e-02, -4.7760e-02,  ...,  7.7259e-02,\n",
      "          -1.1124e-01,  4.2067e-02],\n",
      "         [-1.6939e-03, -1.2971e-02, -4.7825e-02,  ...,  1.0069e-01,\n",
      "          -5.4887e-02,  4.1695e-02],\n",
      "         [-4.2314e-02,  3.4283e-02, -1.7020e-02,  ...,  9.1331e-02,\n",
      "          -1.1599e-01,  2.6414e-02],\n",
      "         ...,\n",
      "         [-1.5012e-02,  6.6912e-03, -3.6249e-02,  ...,  1.0078e-01,\n",
      "          -8.1991e-02,  1.2379e-02],\n",
      "         [ 1.4857e-04, -8.7769e-03, -7.0209e-02,  ...,  1.1244e-01,\n",
      "          -5.3834e-02,  7.4302e-03],\n",
      "         [-2.4246e-02, -1.0225e-02, -6.5351e-02,  ...,  7.3573e-02,\n",
      "          -1.0046e-01,  1.8253e-02]],\n",
      "\n",
      "        [[ 3.2377e-02,  5.0981e-02, -6.1298e-02,  ...,  3.2288e-02,\n",
      "          -9.3251e-02,  1.3938e-02],\n",
      "         [ 4.0059e-02,  6.1457e-02, -6.2907e-02,  ...,  4.0032e-02,\n",
      "          -9.5380e-02,  3.3521e-02],\n",
      "         [ 4.3143e-02,  5.9210e-02, -9.2562e-02,  ...,  2.8273e-02,\n",
      "          -8.0597e-02,  3.9940e-02],\n",
      "         ...,\n",
      "         [ 5.1159e-02,  6.5177e-02, -8.3698e-02,  ...,  3.7730e-02,\n",
      "          -9.6801e-02,  3.3091e-02],\n",
      "         [ 5.5026e-02,  6.4164e-02, -5.7054e-02,  ...,  4.0934e-02,\n",
      "          -7.8588e-02,  4.3632e-02],\n",
      "         [ 5.1164e-02,  7.3913e-02, -5.6551e-02,  ...,  2.3789e-02,\n",
      "          -7.8444e-02,  5.1349e-02]],\n",
      "\n",
      "        [[ 9.1483e-02,  2.6004e-02, -4.3776e-02,  ...,  2.1736e-02,\n",
      "          -1.6335e-01, -2.4522e-02],\n",
      "         [ 8.8538e-02,  5.0724e-02, -9.1579e-03,  ...,  5.1709e-02,\n",
      "          -1.3864e-01, -5.3533e-03],\n",
      "         [ 1.0447e-01,  6.7924e-02, -2.9450e-02,  ...,  3.6477e-02,\n",
      "          -1.2364e-01,  1.2954e-02],\n",
      "         ...,\n",
      "         [ 5.7680e-02,  2.4300e-02, -2.1548e-02,  ...,  5.5740e-02,\n",
      "          -1.5162e-01, -1.0755e-02],\n",
      "         [ 9.0747e-02,  2.0537e-02, -9.3155e-02,  ...,  5.4087e-02,\n",
      "          -1.4958e-01, -1.5711e-02],\n",
      "         [ 8.2907e-02,  4.7483e-02, -5.8679e-02,  ...,  3.2114e-02,\n",
      "          -1.4540e-01, -2.8976e-02]]], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.4582e-02,  9.1344e-02, -1.0687e-01,  ..., -1.0206e-02,\n",
      "          -1.2818e-01, -1.5463e-03],\n",
      "         [-1.8912e-02,  4.0938e-02, -8.7556e-02,  ..., -2.4949e-03,\n",
      "          -1.3941e-01, -4.4411e-03],\n",
      "         [-9.4666e-04,  5.7853e-02, -8.3874e-02,  ...,  1.8113e-02,\n",
      "          -1.0705e-01, -7.6069e-03],\n",
      "         ...,\n",
      "         [-2.4028e-02,  6.3673e-02, -8.2221e-02,  ...,  1.4051e-02,\n",
      "          -1.3951e-01, -3.4789e-03],\n",
      "         [-2.7964e-02,  4.2615e-02, -6.9538e-02,  ...,  6.0354e-03,\n",
      "          -1.4031e-01, -2.2036e-02],\n",
      "         [-3.6167e-02,  8.7227e-02, -8.9230e-02,  ..., -1.4861e-02,\n",
      "          -1.4033e-01,  6.8436e-03]],\n",
      "\n",
      "        [[ 4.3593e-02, -2.5808e-03, -5.2003e-02,  ...,  1.1877e-01,\n",
      "          -6.7161e-02,  4.4058e-02],\n",
      "         [-1.5876e-02, -1.0962e-02, -5.5414e-02,  ...,  1.0821e-01,\n",
      "          -9.6247e-02,  7.5857e-02],\n",
      "         [ 3.9008e-02, -9.9646e-03, -8.8443e-02,  ...,  1.0175e-01,\n",
      "          -6.6031e-02,  3.5053e-02],\n",
      "         ...,\n",
      "         [-4.5003e-04, -2.4214e-02, -8.1430e-02,  ...,  8.0821e-02,\n",
      "          -1.0432e-01,  3.0624e-02],\n",
      "         [ 6.2070e-02,  9.7943e-03, -1.1835e-01,  ...,  9.3977e-02,\n",
      "          -6.3849e-02,  2.5936e-02],\n",
      "         [ 6.4237e-02, -1.1724e-02, -8.8097e-02,  ...,  1.3139e-01,\n",
      "          -7.0058e-02,  4.3121e-02]],\n",
      "\n",
      "        [[ 1.4527e-02,  5.6493e-02, -9.9544e-02,  ...,  5.0305e-02,\n",
      "          -9.1251e-02, -6.8775e-03],\n",
      "         [-1.7120e-02,  7.4424e-02, -7.5350e-02,  ...,  6.2184e-02,\n",
      "          -8.3963e-02,  9.9763e-03],\n",
      "         [ 1.9748e-02,  6.5540e-02, -1.2801e-01,  ...,  6.8864e-02,\n",
      "          -8.3345e-02,  1.9294e-02],\n",
      "         ...,\n",
      "         [ 1.6491e-02,  6.8316e-02, -1.3932e-01,  ..., -4.0194e-03,\n",
      "          -7.6900e-02,  3.6319e-02],\n",
      "         [ 3.4846e-02,  6.7650e-02, -1.2645e-01,  ...,  4.3084e-02,\n",
      "          -4.7550e-02, -9.6150e-03],\n",
      "         [ 1.4527e-02,  5.6493e-02, -9.9544e-02,  ...,  5.0305e-02,\n",
      "          -9.1251e-02, -6.8775e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.8944e-02, -2.8610e-02,  4.2889e-03,  ...,  5.5369e-03,\n",
      "          -7.5396e-02,  6.3321e-02],\n",
      "         [ 9.8423e-05,  1.8553e-02, -1.9758e-02,  ..., -2.3338e-04,\n",
      "          -1.1245e-01,  2.0113e-02],\n",
      "         [ 2.9439e-04, -2.1916e-03,  1.0251e-03,  ...,  3.0163e-02,\n",
      "          -1.0654e-01,  4.3059e-02],\n",
      "         ...,\n",
      "         [ 2.0971e-02, -3.6413e-02, -7.0345e-03,  ..., -6.3203e-03,\n",
      "          -7.9574e-02,  1.6431e-02],\n",
      "         [-2.2481e-02,  3.0327e-02,  1.1592e-02,  ...,  1.1702e-02,\n",
      "          -1.1503e-01,  4.7857e-02],\n",
      "         [-2.9734e-02,  3.4252e-02,  1.7441e-02,  ...,  2.5049e-04,\n",
      "          -1.1940e-01,  9.2581e-02]],\n",
      "\n",
      "        [[ 2.2677e-02,  3.4612e-02, -4.9690e-02,  ...,  5.4155e-04,\n",
      "          -4.3034e-02,  2.0377e-02],\n",
      "         [ 1.7351e-02,  4.0857e-02, -6.1631e-02,  ..., -2.1002e-02,\n",
      "          -3.2325e-02,  2.9979e-02],\n",
      "         [ 4.6671e-02,  5.2820e-02, -3.9265e-02,  ...,  1.4731e-02,\n",
      "          -3.5080e-02,  2.6907e-02],\n",
      "         ...,\n",
      "         [ 1.8541e-02,  4.9004e-02, -4.6901e-02,  ..., -6.5176e-03,\n",
      "          -2.0346e-02,  6.9497e-02],\n",
      "         [ 4.4599e-02,  1.2376e-02, -5.4215e-02,  ..., -3.7546e-02,\n",
      "          -4.0612e-02,  2.6212e-02],\n",
      "         [ 3.3980e-02,  2.5111e-02, -5.3695e-02,  ..., -2.9260e-02,\n",
      "          -1.5213e-02,  3.6377e-02]],\n",
      "\n",
      "        [[-4.7846e-02,  6.3978e-02, -1.4395e-01,  ...,  2.1237e-02,\n",
      "          -1.2275e-01, -1.0934e-02],\n",
      "         [-2.1163e-02,  7.4427e-02, -1.1295e-01,  ...,  2.6436e-02,\n",
      "          -1.3937e-01, -7.4336e-04],\n",
      "         [-3.2394e-02,  7.1091e-02, -1.2495e-01,  ...,  4.7012e-02,\n",
      "          -1.2218e-01, -6.9400e-03],\n",
      "         ...,\n",
      "         [-3.8431e-02,  1.0577e-01, -1.1228e-01,  ...,  1.1422e-02,\n",
      "          -1.0028e-01,  5.2968e-03],\n",
      "         [-2.7623e-02,  9.0785e-02, -1.4346e-01,  ...,  3.3537e-02,\n",
      "          -9.2284e-02,  1.0533e-02],\n",
      "         [-8.5387e-03,  6.2397e-02, -9.1966e-02,  ...,  6.3682e-02,\n",
      "          -1.0764e-01, -6.7144e-03]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 2.7010e-02,  4.9424e-02, -5.4276e-02,  ...,  4.9847e-02,\n",
      "          -1.3400e-01, -5.9383e-02],\n",
      "         [ 3.4699e-02,  5.3514e-02, -5.6882e-02,  ...,  5.3295e-02,\n",
      "          -1.5100e-01, -6.2357e-02],\n",
      "         [ 6.7126e-02,  2.7036e-02, -4.8035e-02,  ...,  3.8019e-02,\n",
      "          -1.6579e-01, -5.2071e-02],\n",
      "         ...,\n",
      "         [ 2.8825e-02,  1.3871e-02, -1.6538e-02,  ...,  3.0892e-02,\n",
      "          -1.4966e-01, -4.3844e-02],\n",
      "         [ 5.2063e-02,  3.5250e-02, -1.7582e-02,  ...,  7.6015e-02,\n",
      "          -1.8518e-01, -5.8021e-02],\n",
      "         [ 1.4051e-02,  2.3802e-02, -1.3818e-02,  ...,  5.1418e-02,\n",
      "          -1.8366e-01, -1.6820e-02]],\n",
      "\n",
      "        [[-3.6518e-02, -5.4703e-02, -1.0944e-02,  ..., -1.2991e-03,\n",
      "          -1.1857e-01,  7.2490e-02],\n",
      "         [ 1.4157e-02, -5.0047e-02, -1.8032e-03,  ...,  1.8731e-02,\n",
      "          -5.8009e-02,  5.4606e-02],\n",
      "         [-2.0785e-02, -6.9273e-02, -1.2446e-02,  ...,  7.5431e-03,\n",
      "          -7.2685e-02,  4.0922e-02],\n",
      "         ...,\n",
      "         [ 2.4570e-02, -5.2475e-02, -3.4095e-02,  ...,  1.8560e-02,\n",
      "          -6.1219e-02,  6.8839e-02],\n",
      "         [-1.6711e-02, -4.2865e-02,  1.1789e-02,  ...,  6.3943e-03,\n",
      "          -8.8426e-02,  4.8487e-02],\n",
      "         [-7.1540e-03, -2.1396e-02,  1.4323e-03,  ...,  2.6192e-02,\n",
      "          -7.4457e-02,  6.1360e-02]],\n",
      "\n",
      "        [[-2.0335e-02,  1.9458e-02, -3.9908e-02,  ...,  2.2024e-02,\n",
      "          -1.5920e-01, -5.6838e-02],\n",
      "         [ 6.9455e-03,  1.2693e-02, -7.5260e-02,  ...,  1.0649e-02,\n",
      "          -1.3729e-01, -3.5076e-02],\n",
      "         [ 1.9177e-03,  7.8978e-02, -8.5009e-02,  ..., -4.4186e-02,\n",
      "          -1.6943e-01,  1.0630e-02],\n",
      "         ...,\n",
      "         [ 3.5177e-02,  5.2833e-02, -7.7565e-02,  ...,  6.2309e-03,\n",
      "          -1.3829e-01, -2.3480e-02],\n",
      "         [ 2.0436e-02,  5.3233e-02, -6.8787e-02,  ...,  1.9515e-02,\n",
      "          -1.5172e-01, -5.3569e-02],\n",
      "         [ 3.5177e-02,  5.2833e-02, -7.7565e-02,  ...,  6.2309e-03,\n",
      "          -1.3829e-01, -2.3480e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.4730e-02,  1.7486e-02, -4.2632e-02,  ...,  5.2909e-02,\n",
      "          -1.3632e-01,  2.3540e-02],\n",
      "         [-5.2331e-02,  1.2484e-04, -4.7290e-02,  ...,  4.0123e-02,\n",
      "          -1.1419e-01,  3.9360e-02],\n",
      "         [ 6.9809e-03, -9.2662e-03, -4.9489e-02,  ...,  5.8511e-02,\n",
      "          -1.2517e-01, -2.8591e-03],\n",
      "         ...,\n",
      "         [-5.2043e-02,  1.1291e-02, -7.2896e-02,  ...,  2.9047e-02,\n",
      "          -8.4568e-02,  4.1857e-02],\n",
      "         [-6.7081e-02,  1.8782e-02, -2.5550e-02,  ...,  6.2271e-02,\n",
      "          -1.6541e-01,  3.6304e-02],\n",
      "         [-7.3701e-02,  6.0517e-02, -2.9292e-02,  ...,  6.2730e-02,\n",
      "          -9.4286e-02,  5.4565e-02]],\n",
      "\n",
      "        [[-4.2088e-03,  3.2662e-02,  7.7467e-03,  ..., -2.8348e-02,\n",
      "          -1.7999e-01, -5.9551e-02],\n",
      "         [-8.8040e-04,  1.4295e-02, -6.1261e-03,  ..., -1.8603e-02,\n",
      "          -1.7372e-01, -4.0427e-02],\n",
      "         [-9.4631e-03,  3.8429e-02, -2.5808e-02,  ..., -5.9949e-02,\n",
      "          -1.6499e-01, -5.2647e-02],\n",
      "         ...,\n",
      "         [ 1.5993e-02,  7.6074e-02, -2.3172e-02,  ..., -7.4226e-02,\n",
      "          -1.4553e-01, -6.3724e-02],\n",
      "         [ 9.1990e-03,  3.3516e-02, -2.6444e-02,  ..., -2.1182e-02,\n",
      "          -1.6837e-01, -8.4712e-02],\n",
      "         [ 1.9947e-02,  3.8808e-02, -3.0572e-02,  ..., -4.0596e-02,\n",
      "          -1.6124e-01, -6.7629e-02]],\n",
      "\n",
      "        [[-2.0107e-02,  4.4572e-02, -1.0228e-01,  ...,  1.5145e-02,\n",
      "          -1.3902e-01, -1.5510e-03],\n",
      "         [-1.1006e-02,  5.0328e-02, -1.2253e-01,  ...,  7.6403e-03,\n",
      "          -1.2878e-01,  2.8862e-02],\n",
      "         [ 4.9046e-03,  3.2164e-02, -1.0234e-01,  ...,  2.0140e-02,\n",
      "          -1.3125e-01,  1.0328e-02],\n",
      "         ...,\n",
      "         [-1.6452e-02,  2.9298e-02, -7.5672e-02,  ...,  5.4235e-02,\n",
      "          -1.1686e-01, -2.3252e-02],\n",
      "         [-2.1743e-02,  7.5101e-02, -1.3867e-01,  ..., -8.1206e-03,\n",
      "          -1.4878e-01,  3.3986e-02],\n",
      "         [-1.0578e-02,  1.9298e-02, -1.1217e-01,  ...,  2.0497e-02,\n",
      "          -1.1484e-01, -1.0281e-02]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.0378,  0.0138, -0.0192,  ...,  0.0852, -0.1476,  0.0062],\n",
      "         [ 0.0935, -0.0005, -0.0060,  ...,  0.0750, -0.1394,  0.0289],\n",
      "         [ 0.0305,  0.0039, -0.0485,  ...,  0.0602, -0.1994,  0.0813],\n",
      "         ...,\n",
      "         [ 0.0789,  0.0378, -0.0401,  ...,  0.0774, -0.1523,  0.0741],\n",
      "         [ 0.0935, -0.0005, -0.0060,  ...,  0.0750, -0.1394,  0.0289],\n",
      "         [ 0.0921, -0.0252, -0.0242,  ...,  0.0765, -0.1345, -0.0057]],\n",
      "\n",
      "        [[-0.0143, -0.0020, -0.1169,  ...,  0.0424, -0.0930, -0.0546],\n",
      "         [ 0.0091,  0.0248, -0.1262,  ...,  0.1066, -0.0968, -0.0138],\n",
      "         [ 0.0086,  0.0188, -0.1204,  ...,  0.0714, -0.0922, -0.0442],\n",
      "         ...,\n",
      "         [-0.0159,  0.0290, -0.1431,  ...,  0.0396, -0.0651, -0.0496],\n",
      "         [ 0.0183,  0.0108, -0.1392,  ...,  0.1004, -0.0528, -0.0338],\n",
      "         [ 0.0115,  0.0412, -0.0886,  ...,  0.0684, -0.0654, -0.0408]],\n",
      "\n",
      "        [[-0.0557,  0.0429, -0.0804,  ...,  0.0432, -0.1515, -0.0243],\n",
      "         [-0.0458,  0.0503, -0.0741,  ...,  0.0469, -0.1555, -0.0276],\n",
      "         [-0.0360,  0.0390, -0.0426,  ...,  0.0804, -0.1378, -0.0178],\n",
      "         ...,\n",
      "         [-0.0226,  0.0863, -0.0776,  ...,  0.0558, -0.1657, -0.0014],\n",
      "         [-0.0528,  0.0849, -0.0800,  ...,  0.0444, -0.1470, -0.0049],\n",
      "         [-0.0518,  0.0380, -0.0703,  ...,  0.0661, -0.1706,  0.0418]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0141, -0.0031, -0.0331,  ...,  0.0088, -0.0751,  0.0255],\n",
      "         [ 0.0133,  0.0383, -0.0482,  ..., -0.0064, -0.0433,  0.0247],\n",
      "         [-0.0103,  0.0396, -0.0605,  ...,  0.0114, -0.0701,  0.0115],\n",
      "         ...,\n",
      "         [-0.0103,  0.0396, -0.0605,  ...,  0.0114, -0.0701,  0.0115],\n",
      "         [ 0.0283,  0.0029, -0.0308,  ...,  0.0197, -0.0606,  0.0278],\n",
      "         [ 0.0149,  0.0069, -0.0555,  ...,  0.0023, -0.0649,  0.0291]],\n",
      "\n",
      "        [[-0.0578,  0.1720, -0.0699,  ...,  0.0638, -0.1241, -0.0342],\n",
      "         [-0.0726,  0.1488, -0.0601,  ...,  0.0975, -0.1590, -0.0270],\n",
      "         [-0.0628,  0.1239, -0.0662,  ...,  0.0843, -0.1515, -0.0263],\n",
      "         ...,\n",
      "         [-0.0643,  0.1423, -0.0301,  ...,  0.0872, -0.1761, -0.0191],\n",
      "         [-0.0467,  0.1164, -0.0998,  ...,  0.0772, -0.1311, -0.0594],\n",
      "         [-0.0792,  0.1359, -0.0360,  ...,  0.0802, -0.1946,  0.0211]],\n",
      "\n",
      "        [[-0.0033,  0.0189, -0.0147,  ...,  0.0086, -0.1388, -0.0250],\n",
      "         [ 0.0033, -0.0170, -0.0251,  ..., -0.0566, -0.1294, -0.0292],\n",
      "         [ 0.0160,  0.0162, -0.0572,  ..., -0.0368, -0.0757, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0247, -0.0158, -0.0399,  ..., -0.0494, -0.0900, -0.0674],\n",
      "         [ 0.0276, -0.0042, -0.0167,  ..., -0.0137, -0.0669, -0.0217],\n",
      "         [-0.0069, -0.0283, -0.0123,  ..., -0.0236, -0.1316, -0.0468]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MultiHeadAttention(\n",
    "    vocab_size=len(dls_lm.vocab), \n",
    "    embed_dim=256, \n",
    "    num_heads=4\n",
    ")\n",
    "\n",
    "learn = Learner(\n",
    "    dls_lm, \n",
    "    model, \n",
    "    loss_func=CrossEntropyLossFlat(), \n",
    "    metrics=[accuracy]\n",
    ")\n",
    "\n",
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63e67945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6823)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Example input and target tensors\n",
    "input = torch.randn(3, 5)  # Input tensor with shape (batch_size, num_classes)\n",
    "target = torch.tensor([1, 0, 4])  # Target tensor with shape (batch_size)\n",
    "\n",
    "# Create an instance of CrossEntropyLoss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Compute the cross-entropy loss\n",
    "loss = loss_fn(input, target)\n",
    "\n",
    "print(loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
