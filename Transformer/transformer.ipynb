{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-forecasting\n",
      "  Downloading pytorch_forecasting-1.0.0-py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.9/dist-packages (from pytorch-forecasting) (1.9.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from pytorch-forecasting) (3.6.1)\n",
      "Collecting fastapi>=0.80\n",
      "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lightning<3.0.0,>=2.0.0\n",
      "  Downloading lightning-2.2.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas<=3.0.0,>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-forecasting) (1.5.0)\n",
      "Collecting pytorch-optimizer<3.0.0,>=2.5.1\n",
      "  Downloading pytorch_optimizer-2.12.0-py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.8/155.8 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting optuna<4.0.0,>=3.1.0\n",
      "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn<2.0,>=1.2\n",
      "  Downloading scikit_learn-1.4.1.post1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting statsmodels\n",
      "  Downloading statsmodels-0.14.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch<3.0.0,>=2.0.0\n",
      "  Downloading torch-2.2.1-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from fastapi>=0.80->pytorch-forecasting) (1.9.2)\n",
      "Collecting starlette<0.37.0,>=0.36.3\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=4.8.0\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.9/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (23.0)\n",
      "Collecting lightning-utilities<2.0,>=0.8.0\n",
      "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-2.2.1-py3-none-any.whl (801 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.6/801.6 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.23.4)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.9/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.64.1)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.9/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (5.4.1)\n",
      "Collecting torchmetrics<3.0,>=0.7.0\n",
      "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<2025.0,>=2022.5.0 in /usr/local/lib/python3.9/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2023.1.0)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna<4.0.0,>=3.1.0->pytorch-forecasting) (1.4.41)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas<=3.0.0,>=1.3.0->pytorch-forecasting) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas<=3.0.0,>=1.3.0->pytorch-forecasting) (2022.7.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.1.0)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (3.9.0)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.2.0\n",
      "  Downloading triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch<3.0.0,>=2.0.0->pytorch-forecasting) (3.1.2)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pytorch-forecasting) (1.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pytorch-forecasting) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pytorch-forecasting) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pytorch-forecasting) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pytorch-forecasting) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pytorch-forecasting) (4.38.0)\n",
      "Collecting scipy<2.0,>=1.8\n",
      "  Downloading scipy-1.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.5/38.5 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting patsy>=0.5.4\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Mako\n",
      "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.28.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.9/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.8.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from lightning-utilities<2.0,>=0.8.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (66.1.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.4->statsmodels->pytorch-forecasting) (1.14.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna<4.0.0,>=3.1.0->pytorch-forecasting) (2.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from starlette<0.37.0,>=0.36.3->fastapi>=0.80->pytorch-forecasting) (3.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->pytorch-forecasting) (2.1.2)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (18.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.80->pytorch-forecasting) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.80->pytorch-forecasting) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.26.14)\n",
      "Installing collected packages: mpmath, typing-extensions, triton, sympy, scipy, patsy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, colorlog, starlette, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lightning-utilities, alembic, statsmodels, optuna, nvidia-cusolver-cu12, fastapi, torch, torchmetrics, pytorch-optimizer, pytorch-lightning, lightning, pytorch-forecasting\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.9.2\n",
      "    Uninstalling scipy-1.9.2:\n",
      "      Successfully uninstalled scipy-1.9.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.1.2\n",
      "    Uninstalling scikit-learn-1.1.2:\n",
      "      Successfully uninstalled scikit-learn-1.1.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cu116\n",
      "    Uninstalling torch-1.12.1+cu116:\n",
      "      Successfully uninstalled torch-1.12.1+cu116\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1+cu116 requires torch==1.12.1, but you have torch 2.2.1 which is incompatible.\n",
      "torchaudio 0.12.1+cu116 requires torch==1.12.1, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.2 alembic-1.13.1 colorlog-6.8.2 fastapi-0.110.0 lightning-2.2.1 lightning-utilities-0.10.1 mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 optuna-3.5.0 patsy-0.5.6 pytorch-forecasting-1.0.0 pytorch-lightning-2.2.1 pytorch-optimizer-2.12.0 scikit-learn-1.4.1.post1 scipy-1.12.0 starlette-0.36.3 statsmodels-0.14.1 sympy-1.12 torch-2.2.1 torchmetrics-1.3.1 triton-2.2.0 typing-extensions-4.10.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (0.13.4)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.28.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (66.1.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.30)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.0.11)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.9/dist-packages (3.5.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.9/dist-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.64.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.4.41)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.13.1)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (1.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.10.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pytorch-forecasting\n",
    "%pip install wandb\n",
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import pickle\n",
    "import pytorch_forecasting as pl\n",
    "import wandb\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_interval = 500\n",
    "block_size = 356"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(\n",
    "#    project=\"shell-transformer\",\n",
    "#    config={\n",
    "#        \"learning_rate\": learning_rate,\n",
    "#        \"architecture\": \"Transformer\",\n",
    "#        \"epochs\": max_iters,\n",
    "#        \"embedding_size\": n_embd,\n",
    "#        \"num_heads\": n_head,\n",
    "#        \"num_layers\": n_layer,\n",
    "#        \"block_size\": block_size,\n",
    "#        \"context_size\": context_size,\n",
    "#    },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stoi.pkl\", \"rb\") as fp:\n",
    "    stoi = pickle.load(fp)\n",
    "\n",
    "with open(\"itos.pkl\", \"rb\") as fp:\n",
    "    itos = pickle.load(fp)\n",
    "\n",
    "with open(\"dataset_x.pt\", \"rb\") as fp:\n",
    "    x = torch.load(fp)\n",
    "\n",
    "with open(\"dataset_y.pt\", \"rb\") as fp:\n",
    "    y = torch.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \"\".join([itos[i] for i in l])\n",
    "vocab_size = len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203101"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(x))\n",
    "train_x = x[:n]\n",
    "train_y = y[:n]\n",
    "\n",
    "val_x = x[n:]\n",
    "val_y = y[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split, batch_size):\n",
    "    if split == \"train\":\n",
    "        x = train_x\n",
    "        y = train_y\n",
    "    else:\n",
    "        x = val_x\n",
    "        y = val_y\n",
    "\n",
    "    idx = torch.randint(len(x), (batch_size,))\n",
    "\n",
    "    x = torch.stack([x[i][:block_size] for i in idx])\n",
    "    y = torch.stack([y[i][:block_size] for i in idx])\n",
    "\n",
    "    return x.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_batch(\"train\", 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttentionBlock(nn.Module):\n",
    "    def __init__(self, headSize):\n",
    "        super().__init__()\n",
    "        self.dim = np.sqrt(headSize)\n",
    "\n",
    "        self.linQ = nn.Linear(headSize, headSize, bias=False)\n",
    "        self.linK = nn.Linear(headSize, headSize, bias=False)\n",
    "        self.linV = nn.Linear(headSize, headSize, bias=False)\n",
    "\n",
    "    def forward(self, k, q):\n",
    "\n",
    "        Q = self.linQ(q)\n",
    "        V = self.linV(k)\n",
    "        K = self.linK(k)\n",
    "\n",
    "        K = torch.transpose(K, 1, 2)\n",
    "\n",
    "        weights = (Q @ K) / self.dim\n",
    "        weights = nn.functional.softmax(weights, -1)\n",
    "\n",
    "        return weights @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionBlock(nn.Module):\n",
    "    def __init__(self, headSize):\n",
    "        super().__init__()\n",
    "        self.dim = np.sqrt(headSize)\n",
    "\n",
    "        self.linQ = nn.Linear(headSize, headSize, bias=False)\n",
    "        self.linK = nn.Linear(headSize, headSize, bias=False)\n",
    "        self.linV = nn.Linear(headSize, headSize, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q = self.linQ(x)\n",
    "        V = self.linV(x)\n",
    "        K = self.linK(x)\n",
    "\n",
    "        B, T, C = Q.shape\n",
    "\n",
    "        K = torch.transpose(K, 1, 2)\n",
    "\n",
    "        weights = (Q @ K) / self.dim  # TODO: why divide by dim?\n",
    "\n",
    "        triu = (\n",
    "            torch.triu(torch.ones((T, T)), diagonal=1) == 1\n",
    "        )  # upper triangular matrix of 'True' values with shape (T, T)\n",
    "\n",
    "        triu = triu.to(device)\n",
    "\n",
    "        weights = weights.masked_fill(\n",
    "            triu, -torch.inf\n",
    "        )  # set upper triangular values of self-attention to '-inf'\n",
    "\n",
    "        weights = nn.functional.softmax(\n",
    "            weights, -1\n",
    "        )  # distribute probability over remaining values\n",
    "\n",
    "        return weights @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, numHeads, headSize):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [SelfAttentionBlock(headSize) for _ in range(numHeads)]\n",
    "        )\n",
    "        self.lin = nn.Linear(headSize * numHeads, headSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        return self.lin(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, numHeads, headSize):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [CrossAttentionBlock(headSize) for _ in range(numHeads)]\n",
    "        )\n",
    "        self.lin = nn.Linear(headSize * numHeads, headSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        return self.lin(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, numLayers, embeddingSize, headSize):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                MultiHeadSelfAttention(headSize, embeddingSize),\n",
    "                nn.Linear(embeddingSize, embeddingSize),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(embeddingSize, embeddingSize),\n",
    "                nn.ReLU(),\n",
    "            ]\n",
    "        )\n",
    "        for i in range(numLayers - 1):\n",
    "            self.layers.extend(\n",
    "                [\n",
    "                    MultiHeadSelfAttention(headSize, embeddingSize),\n",
    "                    nn.Linear(embeddingSize, embeddingSize),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(embeddingSize, embeddingSize),\n",
    "                    nn.ReLU(),\n",
    "                ]\n",
    "            )\n",
    "        self.norm = nn.LayerNorm(embeddingSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, MultiHeadSelfAttention):\n",
    "                x = self.norm(x)\n",
    "                x = x + layer(x)\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                x = self.norm(x)\n",
    "                x = x + layer(x)\n",
    "            if isinstance(layer, nn.ReLU):\n",
    "                x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, numLayers, embeddingSize, vocabSize, headSize):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                MultiHeadSelfAttention(headSize, embeddingSize),\n",
    "                # MultiHeadCrossAttention(headSize, embeddingSize),\n",
    "                nn.Linear(embeddingSize, embeddingSize),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(embeddingSize, embeddingSize),\n",
    "                nn.ReLU(),\n",
    "            ]\n",
    "        )\n",
    "        for i in range(numLayers - 1):\n",
    "            self.layers.extend(\n",
    "                [\n",
    "                    MultiHeadSelfAttention(headSize, embeddingSize),\n",
    "                    # MultiHeadCrossAttention(headSize, embeddingSize),\n",
    "                    nn.Linear(embeddingSize, embeddingSize),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(embeddingSize, embeddingSize),\n",
    "                    nn.ReLU(),\n",
    "                ]\n",
    "            )\n",
    "        self.linear = nn.Linear(embeddingSize, vocabSize)\n",
    "        self.softmax = nn.Softmax(-1)\n",
    "        self.norm = nn.LayerNorm(embeddingSize)\n",
    "\n",
    "    def forward(self, code, x):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, CrossAttentionBlock):\n",
    "                # x = self.norm(x)\n",
    "                # x = x + layer(x, code)\n",
    "                pass\n",
    "            if isinstance(layer, MultiHeadSelfAttention):\n",
    "                x = self.norm(x)\n",
    "                x = x + layer(x)\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                x = self.norm(x)\n",
    "                x = x + layer(x)\n",
    "            if isinstance(layer, nn.ReLU):\n",
    "                x = layer(x)\n",
    "\n",
    "        x = self.linear(x)  # (B, T, vocab_size)\n",
    "\n",
    "        return x  # self.softmax(x) # => predicts for each token, what token should come next (therefore \"prob-distribution\" using softmax for each token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        numLayersEncoder,\n",
    "        numLayersDecoder,\n",
    "        embeddingSize,\n",
    "        headSize,\n",
    "        vocabSize=vocab_size,\n",
    "        maxBlockSize=block_size,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder(numLayersEncoder, embeddingSize, headSize)\n",
    "        self.decoder = TransformerDecoder(\n",
    "            numLayersDecoder, embeddingSize, vocabSize, headSize\n",
    "        )\n",
    "        self.embed = nn.Embedding(vocabSize, embeddingSize)\n",
    "        self.positional_encoding = nn.Embedding(\n",
    "            maxBlockSize, embeddingSize\n",
    "        )  # table containing embedding for each possible token position\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.shape\n",
    "        x = self.embed(x)  # B, T, C\n",
    "        pos_embed = self.positional_encoding(torch.arange(T).to(device))  # T, C\n",
    "        x = x + pos_embed  # B, T, C\n",
    "        # context = self.embed(context)\n",
    "        # code = self.encoder(context)\n",
    "        logits = self.decoder(None, x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sum(p.numel() for p in m.parameters()) / 1e6, \"M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model, eval_iters, batch_size):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, batch_size)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-13 12:10:53,240] A new study created in memory with name: no-name-781d78e5-e262-4d00-b8d4-c0f7f599f157\n",
      "[I 2024-03-13 12:18:00,661] Trial 0 finished with value: 0.16033637523651123 and parameters: {'batch_size': 32, 'lr': 0.00037478634885334535, 'n_embd': 96, 'n_head': 10, 'n_layer': 5, 'max_iters': 836}. Best is trial 0 with value: 0.16033637523651123.\n",
      "[I 2024-03-13 12:29:38,713] Trial 1 finished with value: 0.6072407364845276 and parameters: {'batch_size': 39, 'lr': 2.2599373182713967e-05, 'n_embd': 87, 'n_head': 10, 'n_layer': 8, 'max_iters': 1254}. Best is trial 0 with value: 0.16033637523651123.\n",
      "[I 2024-03-13 12:48:22,599] Trial 2 finished with value: 0.42194443941116333 and parameters: {'batch_size': 56, 'lr': 0.0007125677373199463, 'n_embd': 58, 'n_head': 9, 'n_layer': 8, 'max_iters': 1886}. Best is trial 0 with value: 0.16033637523651123.\n",
      "[I 2024-03-13 12:54:36,627] Trial 3 finished with value: 0.42065030336380005 and parameters: {'batch_size': 32, 'lr': 0.0009931775568588512, 'n_embd': 54, 'n_head': 5, 'n_layer': 9, 'max_iters': 850}. Best is trial 0 with value: 0.16033637523651123.\n",
      "[I 2024-03-13 13:05:55,448] Trial 4 finished with value: 0.16475242376327515 and parameters: {'batch_size': 17, 'lr': 0.00018721645006448427, 'n_embd': 76, 'n_head': 7, 'n_layer': 8, 'max_iters': 1732}. Best is trial 0 with value: 0.16033637523651123.\n",
      "[I 2024-03-13 13:16:28,813] Trial 5 finished with value: 0.19663234055042267 and parameters: {'batch_size': 9, 'lr': 0.0007052872223921162, 'n_embd': 82, 'n_head': 7, 'n_layer': 6, 'max_iters': 1820}. Best is trial 0 with value: 0.16033637523651123.\n",
      "[I 2024-03-13 13:24:42,361] Trial 6 finished with value: 0.414511114358902 and parameters: {'batch_size': 39, 'lr': 0.0009545816004350278, 'n_embd': 59, 'n_head': 8, 'n_layer': 8, 'max_iters': 872}. Best is trial 0 with value: 0.16033637523651123.\n",
      "[I 2024-03-13 13:38:09,338] Trial 7 finished with value: 0.17413130402565002 and parameters: {'batch_size': 15, 'lr': 0.0003368266564914902, 'n_embd': 68, 'n_head': 7, 'n_layer': 10, 'max_iters': 1372}. Best is trial 0 with value: 0.16033637523651123.\n",
      "[I 2024-03-13 13:42:33,466] Trial 8 finished with value: 0.16859453916549683 and parameters: {'batch_size': 62, 'lr': 0.0006698330228750786, 'n_embd': 51, 'n_head': 7, 'n_layer': 7, 'max_iters': 589}. Best is trial 0 with value: 0.16033637523651123.\n",
      "[I 2024-03-13 13:44:19,058] Trial 9 finished with value: 0.18221379816532135 and parameters: {'batch_size': 57, 'lr': 0.00048286357432020363, 'n_embd': 100, 'n_head': 9, 'n_layer': 3, 'max_iters': 274}. Best is trial 0 with value: 0.16033637523651123.\n",
      "[I 2024-03-13 13:45:50,567] Trial 10 finished with value: 0.19768817722797394 and parameters: {'batch_size': 28, 'lr': 0.0003710305243308131, 'n_embd': 100, 'n_head': 10, 'n_layer': 4, 'max_iters': 251}. Best is trial 0 with value: 0.16033637523651123.\n",
      "[I 2024-03-13 13:52:23,155] Trial 11 finished with value: 0.17391985654830933 and parameters: {'batch_size': 21, 'lr': 0.00010014622158385418, 'n_embd': 88, 'n_head': 5, 'n_layer': 5, 'max_iters': 1561}. Best is trial 0 with value: 0.16033637523651123.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 8, 64)\n",
    "    learning_rate = lr = trial.suggest_float(\"lr\", 0.00001, 0.001)\n",
    "    eval_iters = 200\n",
    "    n_embd = trial.suggest_int(\"n_embd\", 50, 100)\n",
    "    n_head = trial.suggest_int(\"n_head\", 5, 10)\n",
    "    n_layer = trial.suggest_int(\"n_layer\", 3, 10)\n",
    "    max_iters = trial.suggest_int(\"max_iters\", 100, 2000)\n",
    "\n",
    "    model = Transformer(n_layer, n_layer, n_embd, n_head).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for iter in range(max_iters):\n",
    "\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "            losses = estimate_loss(model, eval_iters, batch_size)\n",
    "            # print(\n",
    "            #    f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\"\n",
    "            # )\n",
    "            # wandb.log({\"loss\": losses[\"train\"], \"val_loss\": losses[\"val\"]})\n",
    "\n",
    "        xb, yb = get_batch(\"train\", batch_size)\n",
    "\n",
    "        with torch.autocast(device_type=device):\n",
    "            logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return losses[\"val\"]\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "study.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
